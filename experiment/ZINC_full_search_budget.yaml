seml:
  executable: experiment_fragmentation.py
  name: ZINC_full_search_budget
  output_dir: seml_output
  project_root_dir: /ceph/ssd/staff/wollschl/substructure-gnns
#  description: A first test.

slurm:
  experiments_per_job: 3
  max_simultaneous_jobs: 8  # Restrict number of simultaneously running jobs per job array
  sbatch_options:
    gres: gpu:1       # num GPUs
    #mem: 16G          # memory
    mem: 64G          # memory
    #cpus-per-task: 4  # num cores
    cpus-per-task: 9  # num cores
    #time: 0-00:55     # max time, D-HH:MM
    time: 8-00:00
    partition: ['gpu_limited']
    exclude: gpu04,gpu12,gpu13,gpu08,gpu10

###### BEGIN PARAMETER CONFIGURATION ######

fixed:
  project_name: "ZINC_full_search"
  trainer_params:
    max_epochs: 1000
    testing: False
    min_lr: 1e-8

  data:
    #seed: 40
    dataset_params.dataset_seed: 0
    loader_params:
      batch_size: 128
      num_workers: 4
    dataset: "ZINC-full"
    #dataset: "ZINC" #TODO: change back to ZINC-full
    one_hot_edge_features: False
    one_hot_node_features: False
    fragmentation_method: ["RingsPaths", "higher_level_graph_tree", {"vocab_size": 30, "max_ring": 15}]
    
  model:
    model_type: "HimpNetSmall"
    classification: False
    model_params:
      hidden_channels: 120
      dropout: 0
      num_layers: 3
      inter_message_passing: True
      higher_message_passing: True
      encoding_size_scaling: True
      degree_scaling: False
      learned_edge_rep: True
      inter_message_params.reduction: "mean"
      reduction: "sum"
      atom_feature_params:
        num_atom_types: 30
        num_atom_features: 1
      edge_feature_params:
        num_bond_types: 4
        num_bond_features: 1
      #rbf: 20
      #concat: False


  optimization:
    # optimization_params:
    #   lr: 0.001
      #weight_decay: 5e-4
    loss: "mae"
    scheduler_parameters:
      mode: "min"
      factor: 0.9
      cooldown: 5

grid:
  trainer_params:
    gradient_clip_val:
      type: choice
      options:
        - 1

  optimization.scheduler_parameters.patience:
    type: choice
    options:
      - 5
      - 15

  optimization.optimization_params.lr:
    type: choice
    options:
      - 0.0001
      - 0.001
      #- 0.0001
      #- 0.01
  
  optimization.ema_decay:
    type: choice
    options:
      - 0.99
      #- 0.999
      #- None

  
  model.model_params.frag_reduction:
    type: choice
    options:
      #- "sum"
      - "max"
 
  data.seed:
    type: choice
    options:
      - 23
      - 24
      - 25
  





  

  
