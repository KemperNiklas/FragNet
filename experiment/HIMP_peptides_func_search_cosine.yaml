seml:
  executable: experiment_fragmentation.py
  name: HIMP_peptides_func_search_cosine
  output_dir: /ceph/hdd/students/kempern/experiment/logs/HIMP_peptides_func_search_cosine
  project_root_dir: ~/substructure-gnns
  conda_environment: substructureML2
#  description: A first test.

slurm:
  experiments_per_job: 3
  max_simultaneous_jobs: 6  # Restrict number of simultaneously running jobs per job array
  sbatch_options:
    gres: gpu:1       # num GPUs
    #mem: 16G          # memory
    mem: 64G          # memory
    #cpus-per-task: 4  # num cores
    cpus-per-task: 9  # num cores
    #time: 0-00:55     # max time, D-HH:MM
    time: 0-09:00
    partition: gpu_all
    #exclude: gpu04,gpu12,gpu13,gpu08,gpu10,mdsi-gpu01,mdsi-gpu02

###### BEGIN PARAMETER CONFIGURATION ######
fixed:
  project_name: "peptides func search cosine"
  trainer_params:
    max_epochs: 300
    testing: False
    min_lr: 1e-6
    monitor: "val_average_multilabel_precision"
    patience_early_stopping: 400

  data:
    dataset_params.dataset_seed: 0
    loader_params:
      batch_size: 32
      num_workers: 4
      val_batch_size: 3000
    dataset: "peptides-func"
    one_hot_edge_features: False
    one_hot_node_features: False
    fragmentation_method: ["RingsPaths", "higher_level_graph_tree", {"vocab_size": 30, "max_ring": 15}]
    
  model:
    model_type: "HimpNetSmall"
    classification: True
    model_params:
      #dropout: 0.15
      out_channels: 10
      #num_layers: 3
      inter_message_passing: True
      higher_message_passing: True
      encoding_size_scaling: True
      degree_scaling: False
      learned_edge_rep: True
      inter_message_params.reduction: "mean"
      atom_feature_params:
        num_atom_types: 20
        num_atom_features: 9
      edge_feature_params:
        num_bond_types: 4
        num_bond_features: 3
    

  optimization:
    optimization_params:
      weight_decay: 0
    additional_metric: "ap"
    scheduler_parameters:
      name: "cosine_with_warmup"
      num_warmup_epochs: 20
      max_epochs: 300 #has to be changed above too
      min_lr: 1e-6

grid:
  optimization.optimization_params.lr:
    type: choice
    options:
      - 0.003
      #- 0.001

  model.model_params.hidden_channels:
    type: choice
    options:
      #- 128
      #- 90
      - 64
    zip_id: layers

  trainer_params:
    gradient_clip_val:
      type: choice
      options:
        - 1
  
  optimization.ema_decay:
    type: choice
    options:
      - 0.99
      #- 0.999
      #- None

  model.model_params.num_layers_out:
    type: choice
    options:
      #- 2
      - 3

  model.model_params.frag_reduction:
    type: choice
    options:
      - "sum"
      #- "max"
  
  model.model_params.reduction:
    type: choice
    options:
      - "mean"
      - "sum"

  model.model_params.num_layers:
    type: choice
    options:
      - 2
      #- 3
      #- 4
    zip_id: layers
  

  model.model_params.dropout:
    type: choice
    options:
      #- 0
      #- 0.1
      - 0.15
      #- 0.2

  data.seed:
    type: choice
    options:
      - 23
      - 24
      - 25



  





  

  
